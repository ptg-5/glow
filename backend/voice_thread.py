import sys
import time
from PyQt5.QtCore import QThread, pyqtSignal

from hailo_platform import VDevice
from backend.stt import RealtimeSTT
from backend.llm import LLMResponseGenerator

class VoiceWorker(QThread):
    status_signal = pyqtSignal(str)
    user_text_signal = pyqtSignal(str)
    
    # [ìˆ˜ì •] ìŠ¤íŠ¸ë¦¬ë°ìš© ì‹ í˜¸ë“¤
    ai_start_signal = pyqtSignal()      # ë§í’ì„  ìƒì„±
    ai_chunk_signal = pyqtSignal(str)   # ê¸€ì ì¶”ê°€
    finished_signal = pyqtSignal()      # ì¢…ë£Œ

    def __init__(self, mode="VOICE", input_text=""):
        super().__init__()
        self.whisper_path = "/home/intelai/hailo/.venv/lib/python3.11/site-packages/hailo_tutorials/hefs/Whisper-Base.hef"
        self.llm_path = "/home/intelai/hailo/.venv/lib/python3.11/site-packages/hailo_tutorials/hefs/Qwen2-1.5B-Instruct.hef"
        
        self.running = False
        self.skin_context = "ì•„ì§ ì¸¡ì •ëœ í”¼ë¶€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        self.mode = mode
        self.input_text = input_text

    def set_context(self, skin_data):
        if not skin_data: return
        desc = "ì‚¬ìš©ìì˜ í˜„ì¬ í”¼ë¶€ ìƒíƒœ:\n"
        part_map = {"chin":"í„±", "lips":"ì…ìˆ ", "right_cheek":"ìš°ë³¼", "left_cheek":"ì¢Œë³¼", "forehead":"ì´ë§ˆ"}
        for part, scores in skin_data.items():
            kor_part = part_map.get(part, part)
            oil = scores.get('Oil', 0)
            dry = scores.get('Dry', 0)
            desc += f"- {kor_part}: ìœ ë¶„{oil}%, ê±´ì¡°{dry}%\n"
        self.skin_context = desc

    def run(self):
        self.running = True
        try:
            params = VDevice.create_params()
            with VDevice(params) as vdevice:
                user_text = ""

                # 1. ì…ë ¥ ë°›ê¸° (ìŒì„± or í…ìŠ¤íŠ¸)
                if self.mode == "VOICE":
                    self.status_signal.emit("ìŒì„± ëª¨ë¸ ë¡œë”© ì¤‘...")
                    with RealtimeSTT(vdevice, self.whisper_path) as stt:
                        self.status_signal.emit("ğŸ‘‚ ë§ì”€í•´ì£¼ì„¸ìš”!")
                        user_text = stt.wait_and_record(language="ko")
                        if not self.running or not user_text:
                            self.status_signal.emit("ì…ë ¥ ì—†ìŒ")
                            return
                        self.user_text_signal.emit(user_text)
                elif self.mode == "TEXT":
                    user_text = self.input_text

                # 2. LLM ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
                self.status_signal.emit("ğŸ¤” ë‹µë³€ ì‘ì„± ì¤‘...")
                
                with LLMResponseGenerator(vdevice, self.llm_path) as llm:
                    sys_prompt = (
                    "ë‹¹ì‹ ì€ í•œêµ­ì˜ ìœ ëŠ¥í•œ í”¼ë¶€ê³¼ ì „ë¬¸ì˜ 'Dr.Glow'ì…ë‹ˆë‹¤. "
                    "ì‚¬ìš©ìì˜ í”¼ë¶€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì „ë¬¸ì ì´ê³  ì¹œì ˆí•˜ê²Œ ì¡°ì–¸í•´ ì£¼ì„¸ìš”. "
                    "ì ˆëŒ€ë¡œ ì¤‘êµ­ì–´ë‚˜ í•œìë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                    f"[ì‚¬ìš©ì í”¼ë¶€ ë°ì´í„°]\n{self.skin_context}"
                )
                    
                    # [í•µì‹¬] ë§í’ì„  ë¨¼ì € ë§Œë“¤ê³  -> ê¸€ì ì±„ìš°ê¸°
                    self.ai_start_signal.emit()
                    
                    # stream_responseëŠ” generatorì´ë¯€ë¡œ forë¬¸ìœ¼ë¡œ ëŒë¦¼
                    for token in llm.stream_response(user_text, max_tokens=200, system_prompt=sys_prompt):
                        if not self.running: break
                        self.ai_chunk_signal.emit(token)
                        # ë„ˆë¬´ ë¹ ë¥´ë©´ UIê°€ ëª» ë”°ë¼ê°ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ì•„ì£¼ ë¯¸ì„¸í•œ ì§€ì—° (ì„ íƒì‚¬í•­)
                        # time.sleep(0.01) 

        except Exception as e:
            self.status_signal.emit(f"ì˜¤ë¥˜: {str(e)}")
            print(f"Voice Error: {e}")
        
        finally:
            self.finished_signal.emit()
            self.running = False

    def stop(self):
        self.running = False
        self.terminate()
        self.wait()