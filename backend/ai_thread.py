import gi
import time
import numpy as np
import sys
import json
import random
import gc

import uuid 
import os
from collections import defaultdict, Counter
from PyQt5.QtCore import QThread, pyqtSignal, QMutex
from PyQt5.QtGui import QImage

gi.require_version('Gst', '1.0')
from gi.repository import Gst, GLib
import hailo
from backend.database import DBManager

class HailoWorker(QThread):
    change_pixmap_signal = pyqtSignal(QImage)
    status_signal = pyqtSignal(str)
    result_signal = pyqtSignal(dict)
    mirror_ready_signal = pyqtSignal()

    def __init__(self, hef_path, labels_json):
        super().__init__()
        if not Gst.is_initialized(): Gst.init(None)

        # === ëª¨ë¸ ê²½ë¡œ ===
        self.hef_path_yolo = "/home/intelai/hailo/best_yolov8_cdh.hef"
        self.json_path_yolo = "/home/intelai/hailo/hailo-apps-infra/resources/json/cdh_labels.json"
        self.hef_path_skin = "/home/intelai/hailo/mobile_net_han_kernel_shape.hef"
        self.so_path_skin = "/home/intelai/hailo/hailo-apps-infra/skin_post/build/libskin_post.so"
        self.so_path_yolo = "/usr/local/hailo/resources/so/libyolo_hailortpp_postprocess.so"

        self.running = True
        self.pipeline = None
        self.appsink = None
        self.db = DBManager()
        self.mutex = QMutex()

        self.active_mode = None       
        self.requested_mode = 'MIRROR'
        self.measure_state = "IDLE"
        self.start_time = 0
        self.collected_data = defaultdict(list)
        self.required_parts = 1 
        
        self.last_frame = None
        self.last_bboxes = {}
        
        self.skin_type_buffer = []
        self.detected_skin_type = "ë¶„ì„ ì¤‘..."
        self.skin_analysis_start_time = 0
        self.current_user_id = 0

    def set_current_user(self, user_id):
        print(f"set_current_user:{user_id}**************************")
        self.current_user_id = user_id

    def request_start_session(self):
        if self.requested_mode != 'MIRROR': return
        print(">>> [UI] ì¸¡ì • ìš”ì²­ -> 1ë‹¨ê³„: ResNet ë¶„ì„ ì‹œì‘")
        self.status_signal.emit("í”¼ë¶€ íƒ€ì…ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
        
        self.requested_mode = 'SKIN_TYPE'
        self.skin_type_buffer = []
        self.measure_state = "IDLE"
        self.collected_data.clear()
        self.last_bboxes = {}
        self.skin_analysis_start_time = time.time()

    def request_mirror_mode(self):
        if self.requested_mode == 'MIRROR': return
        print(">>> [UI] ê±°ìš¸ ëª¨ë“œ ìš”ì²­")
        self.requested_mode = 'MIRROR'

    def stop_pipeline(self):
        self.mutex.lock()
        try:
            if self.pipeline:
                if self.appsink:
                    try: self.appsink.set_property("emit-signals", False)
                    except: pass
                self.pipeline.set_state(Gst.State.NULL)
                self.pipeline.get_state(1 * Gst.SECOND)
                self.pipeline = None
                self.appsink = None
                gc.collect()
        finally:
            self.mutex.unlock()

    # === [1ë‹¨ê³„] ResNet ===
    def process_skin_type_from_tensor(self, roi):
        # íƒ€ì„ì•„ì›ƒ (3ì´ˆ ì§€ë‚˜ë©´ ê°•ì œ í†µê³¼)
        if time.time() - self.skin_analysis_start_time > 3.0:
            print("âš ï¸ [Timeout] ResNet ì‘ë‹µ ì—†ìŒ -> 2ë‹¨ê³„ ê°•ì œ ì´ë™")
            self.detected_skin_type = "ë³µí•©ì„± (Combination)"
            self.status_signal.emit("íƒ€ì… ë¶„ì„ ì™„ë£Œ (ê¸°ë³¸ê°’) -> ì •ë°€ ì§„ë‹¨")
            self.requested_mode = 'AI'
            self.measure_state = "IDLE" # ìƒíƒœ ì´ˆê¸°í™”
            return

        tensors = roi.get_tensors()
        if not tensors: return 

        tensor = tensors[0]
        data = np.array(tensor.get_data())
        idx = np.argmax(data)
        
        type_map = ["ì§€ì„± (Oily)", "ê±´ì„± (Dry)", "ì¤‘ì„± (Normal)", "ë³µí•©ì„± (Combination)"]
        final_type = type_map[idx % 4]
        
        self.skin_type_buffer.append(final_type)
        
        if len(self.skin_type_buffer) >= 30:
            count = Counter(self.skin_type_buffer)
            top_result = count.most_common(1)[0][0]
            self.detected_skin_type = top_result
            print(f"âœ… [1ë‹¨ê³„ ì™„ë£Œ] í”¼ë¶€ íƒ€ì… í™•ì •: {top_result}")
            self.status_signal.emit(f"íƒ€ì…: {top_result} -> ì •ë°€ ì§„ë‹¨ ì‹œì‘")
            
            self.requested_mode = 'AI'
            self.measure_state = "IDLE" # ìƒíƒœ ì´ˆê¸°í™” (ì¤‘ìš”)

    # === [2ë‹¨ê³„] ì •ë°€ ì§„ë‹¨ ===
    # def parse_skin_label(self, label_str):
    #     try:
    #         if ":" not in label_str: return None, None
    #         parts = label_str.split(":", 1)
    #         part_name = parts[0]; data_str = parts[1]; scores = {}
    #         for item in data_str.split(","):
    #             if ":" in item:
    #                 k, v = item.split(":"); scores[k] = int(v.replace("%", ""))
    #         return part_name, scores
    #     except: return None, None

    # def process_measurement(self, detections):
    #     if self.measure_state in ["STANDBY", "DONE", "PROCESSING"]: return

    #     current_frame_data = {}; current_bboxes = {}; valid_parts_count = 0
    #     target_parts = ["chin", "lips", "right_cheek", "left_cheek", "right_eye", "left_eye", "forehead", "nose", "glabella"]

    #     for det in detections:
    #         label = det.get_label(); bbox = det.get_bbox()
    #         current_bboxes[label] = [bbox.xmin(), bbox.ymin(), bbox.width(), bbox.height()]

    #         # 1. ì •ìƒ ë°ì´í„° (ì ìˆ˜ ìˆìŒ)
    #         if ":" in label:
    #             part_name, scores = self.parse_skin_label(label)
    #             if part_name and scores:
    #                 current_frame_data[part_name] = scores
    #                 if label in current_bboxes: current_bboxes[part_name] = current_bboxes.pop(label)
    #                 valid_parts_count += 1
            
    #         # 2. [ìˆ˜ì •] ì•ˆì „ì¥ì¹˜: ì ìˆ˜ ì—†ì–´ë„ ë¶€ìœ„ ì¸ì‹ë˜ë©´ ë°ì´í„° ì±„ì›Œë„£ìŒ
    #         # (ì´ê²Œ ì—†ìœ¼ë©´ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì˜ì›íˆ ëŒ€ê¸°í•¨)
    #         elif label in target_parts:
    #             valid_parts_count += 1
    #             # ë©ˆì¶¤ ë°©ì§€ìš© ê¸°ë³¸ê°’ ìƒì„±
    #             current_frame_data[label] = {
    #                 "Dry": random.randint(10, 40), "Oil": random.randint(30, 70),
    #                 "Acne": random.randint(0, 30), "Wrinkle": random.randint(0, 50),
    #                 "Pigment": random.randint(0, 20)
    #             }

    #     if current_bboxes: self.last_bboxes = current_bboxes
    #     current_time = time.time()

    #     # ìƒíƒœ ë¨¸ì‹ 
    #     if self.measure_state == "IDLE":
    #         if valid_parts_count >= self.required_parts:
    #             self.measure_state = "READY"; self.start_time = current_time
    #             self.status_signal.emit("âœ… ì–¼êµ´ ì¸ì‹ë¨! ë¶„ì„ ì‹œì‘...")
    #             print(">>> [2ë‹¨ê³„] ì¸¡ì • ì‹œì‘ (READY)")
    #         else: 
    #             # ì¸ì‹ì€ ë˜ëŠ”ë° ë¶€ìœ„ê°€ ëª¨ìë„ ë•Œ
    #             pass

    #     elif self.measure_state == "READY":
    #         if valid_parts_count < self.required_parts:
    #             self.measure_state = "IDLE"; self.status_signal.emit("ì–¼êµ´ì„ ë†“ì³¤ìŠµë‹ˆë‹¤.")
    #         elif current_time - self.start_time > 1.0:
    #             self.measure_state = "MEASURING"; self.start_time = current_time
    #             self.collected_data.clear(); self.status_signal.emit("ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ğŸ“¸")
    #             print(">>> [2ë‹¨ê³„] ë°ì´í„° ìˆ˜ì§‘ ì¤‘ (MEASURING)")

    #     elif self.measure_state == "MEASURING":
    #         elapsed = current_time - self.start_time
    #         progress = min(100, int(elapsed / 5.0 * 100))
    #         self.status_signal.emit(f"ì§„ë‹¨ ì¤‘... {progress}%")
            
    #         for part, scores in current_frame_data.items(): 
    #             self.collected_data[part].append(scores)
            
    #         if elapsed >= 5.0: 
    #             self.finalize_measurement()

    # def finalize_measurement(self):
    #     self.measure_state = "PROCESSING"; print("ğŸ“Š ì¸¡ì • ì™„ë£Œ! ê²°ê³¼ ì§‘ê³„ ì¤‘...")
    #     final_result = {}
        
    #     # ë°ì´í„°ê°€ ë¹„ì—ˆì–´ë„ ë©ˆì¶”ì§€ ì•Šê²Œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¼ë„ ì²˜ë¦¬
    #     if not self.collected_data:
    #         print("âš ï¸ [WARNING] ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ (í•˜ì§€ë§Œ ì¢…ë£Œ ì²˜ë¦¬í•¨)")
    #         # ë¹ˆ ê²°ê³¼ë¼ë„ ë³´ë‚´ì„œ UIê°€ ë©ˆì¶”ì§€ ì•Šê²Œ í•¨
        
    #     total_score = 0; cnt = 0
    #     for part, data_list in self.collected_data.items():
    #         if not data_list: continue
    #         avg_scores = {}; keys = data_list[0].keys()
    #         for k in keys:
    #             vals = [d.get(k, 0) for d in data_list]
    #             avg_val = int(sum(vals) / len(vals))
    #             avg_scores[k] = avg_val
    #             total_score += avg_val; cnt += 1
    #         final_result[part] = avg_scores
        
    #     avg_bad = int(total_score / cnt) if cnt > 0 else 50
    #     summary_score = max(0, 100 - int(avg_bad * 0.8))

    #     # DB ì €ì¥ (main_windowê°€ ë‹´ë‹¹í•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥í•˜ì§€ë§Œ, ì•ˆì „ì„ ìœ„í•´ ë°ì´í„°ë§Œ ìƒì„±)
    #     # self.db.insert_skin_record(...) 

    #     safe_snapshot = self.last_frame.copy() if self.last_frame else None
        
    #     result_pack = {
    #         "score": summary_score,
    #         "time": time.strftime("%Y-%m-%d %H:%M"),
    #         "details": final_result,
    #         "snapshot": safe_snapshot,
    #         "bboxes": self.last_bboxes,
    #         "skin_type": self.detected_skin_type,
    #         "user_id": self.current_user_id
    #     }
        
    #     self.result_signal.emit(result_pack)
    #     self.status_signal.emit("ë¶„ì„ ì™„ë£Œ!")
        
    #     # ê±°ìš¸ ëª¨ë“œ ë³µê·€ ìš”ì²­
    #     self.request_mirror_mode()

    # def _build_pipeline(self, mode):
    #     uid = str(uuid.uuid4().hex)[:8]
    #     print(f"ğŸ› ï¸ íŒŒì´í”„ë¼ì¸ ë¹Œë“œ: {mode} (ID: {uid})")
        
    #     source_pipe = "v4l2src device=/dev/video0 name=source ! videorate ! video/x-raw, framerate=30/1 ! videoflip video-direction=horiz ! "
        
    #     if mode == 'SKIN_TYPE':
    #         main_infer = (
    #             "videoscale ! video/x-raw, width=224, height=224 ! videoconvert ! "
    #             f"hailonet hef-path={self.hef_path_resnet} batch-size=1 vdevice-group-id=1 ! "
    #             "videoscale ! video/x-raw, width=640, height=640 ! videoconvert ! "
    #             "queue leaky=downstream max-size-buffers=3 ! "
    #         )
    #         output = "video/x-raw, format=RGB ! appsink name=qt_sink emit-signals=true sync=false drop=true max-buffers=1 wait-on-eos=false"
    #         pipeline_str = source_pipe + main_infer + output

    #     elif mode == 'AI':
    #         source_pipe += "videoscale ! video/x-raw, width=640, height=640 ! videoconvert ! queue leaky=downstream max-size-buffers=3 ! "
    #         main_infer = f"hailonet name=inference_hailonet hef-path={self.hef_path_yolo} batch-size=1 vdevice-group-id=1 force-writable=true ! hailofilter name=inference_hailofilter so-path={self.so_path_yolo} config-path={self.json_path_yolo} qos=false ! queue leaky=no max-size-buffers=3 ! "
    #         cropper = f"hailocropper name=crop_{uid} so-path={self.so_path_skin} function-name=all_detections use-letterbox=true internal-offset=true hailoaggregator name=agg_{uid} crop_{uid}. ! queue name=q_bypass_{uid} leaky=no max-size-buffers=30 ! agg_{uid}.sink_0 crop_{uid}. ! hailonet hef-path={self.hef_path_skin} batch-size=1 vdevice-group-id=1 ! queue leaky=no ! hailofilter so-path={self.so_path_skin} function-name=skin_regression qos=false ! queue leaky=no ! agg_{uid}.sink_1 agg_{uid}. ! "
    #         output = "queue leaky=downstream max-size-buffers=3 ! identity name=identity_callback ! hailooverlay name=hailo_display_overlay ! videoconvert ! video/x-raw, format=RGB ! appsink name=qt_sink emit-signals=true sync=false drop=true max-buffers=1 wait-on-eos=false"
    #         pipeline_str = source_pipe + main_infer + cropper + output
        
    #     else: # MIRROR
    #         source_pipe += "videoscale ! video/x-raw, width=640, height=640 ! videoconvert ! "
    #         output = "video/x-raw, format=RGB ! appsink name=qt_sink emit-signals=true sync=false drop=true max-buffers=1 wait-on-eos=false"
    #         print(f"   - [Cleanup] ì •ì§€ ì‹œì‘ (Mode: {self.active_mode})")
                
    #         if self.appsink:
    #             try:
    #                 self.appsink.set_property("emit-signals", False)
    #             except: pass
            
    #             self.pipeline.set_state(Gst.State.NULL)
    #             # self.pipeline.get_state(2 * Gst.SECOND)
    #             self.pipeline.get_state(Gst.CLOCK_TIME_NONE)

    #             del self.appsink
    #             del self.pipeline

    #             #self.pipeline.unref()
            
    #             self.pipeline = None
    #             self.appsink = None

    #             # segmentation fault ë°œìƒì— 4ê¸°ì—¬
    #             # gc.collect()
    #             print("   - [Cleanup] ì™„ë£Œ")
    #             except Exception as e:
    #                 print(f"   - [Error] Stop ì¤‘ ì—ëŸ¬: {e}")
    #             finally:
    #                 self.mutex.unlock()

    def _build_pipeline(self, mode):
        # [í•µì‹¬] ë§¤ë²ˆ ê³ ìœ í•œ ì´ë¦„ì„ ìƒì„± (ì¶©ëŒ ë°©ì§€)
        uid = str(uuid.uuid4().hex)[:8] 
        # uid = 1
        name_agg = f"agg_{uid}"
        name_crop = f"cropper_{uid}"
        name_sink0 = f"sink_0" # íŒ¨ë“œ ì´ë¦„ì€ ê³ ì •ì´ì–´ì•¼ í•¨
        name_sink1 = f"sink_1"
        
        print(f"ğŸ› ï¸ íŒŒì´í”„ë¼ì¸ ë¹Œë“œ ì‹œì‘: {mode} (ID: {uid})")
        
        source_pipe = (
            "v4l2src device=/dev/video0 name=source ! "
            "videorate ! video/x-raw, framerate=30/1 ! " 
            "videoflip video-direction=horiz ! "
            "videoscale ! video/x-raw, width=640, height=640 ! "
            "videoconvert ! " 
            "queue leaky=downstream max-size-buffers=3 ! " 
        )
        common_appsink = (
            "appsink name=qt_sink "
            "emit-signals=true "
            "sync=false "
            "drop=true "
            "max-buffers=1 "
            "qos=false "           # â† ì—¬ê¸°ì„œ ë¯¸ë¦¬ ì„¤ì •! (í•µì‹¬!)
            "wait-on-eos=false"
        )

        if mode == 'AI':
            main_infer = (
                f"hailonet name=inference_hailonet hef-path={self.hef_path_yolo} batch-size=1 vdevice-group-id=1 force-writable=true ! "
                f"hailofilter name=inference_hailofilter so-path={self.so_path_yolo} config-path={self.json_path_yolo} qos=false ! "
                "queue leaky=no max-size-buffers=3 ! "
            )
            
            # [ìˆ˜ì •] ê³ ìœ  ì´ë¦„(name_crop, name_agg) ì‚¬ìš©
            cropper = (
                f"hailocropper name={name_crop} so-path={self.so_path_skin} function-name=all_detections use-letterbox=true internal-offset=true hailoaggregator name={name_agg} "
                f"{name_crop}. ! queue name=q_bypass_{uid} leaky=no max-size-buffers=30 ! {name_agg}.{name_sink0} "
                f"{name_crop}. ! hailonet hef-path={self.hef_path_skin} batch-size=1 vdevice-group-id=1 ! queue leaky=no ! hailofilter so-path={self.so_path_skin} function-name=skin_regression qos=false ! queue leaky=no ! {name_agg}.{name_sink1} "
                f"{name_agg}. ! "
            )
            
            output = (
                "queue leaky=downstream max-size-buffers=3 ! "
                "identity name=identity_callback ! "
                "hailooverlay name=hailo_display_overlay ! " 
                "videoconvert ! "
                "video/x-raw, format=RGB ! " 
                f"{common_appsink}"
            )
            pipeline_str = source_pipe + main_infer + cropper + output
        else:
            output = (
                "videoconvert ! "
                "video/x-raw, format=RGB ! " 
                f"{common_appsink}"
            )
            pipeline_str = source_pipe + output

        try:
            pipeline = Gst.parse_launch(pipeline_str)
            appsink = pipeline.get_by_name("qt_sink")
            if not appsink: return None, None
            appsink.set_property("sync", False); appsink.set_property("drop", True); appsink.set_property("max-buffers", 1); appsink.set_property("qos", False)
            return pipeline, appsink
        # except: return None, None

            # appsink.set_property("sync", False)
            # appsink.set_property("drop", True)
            # appsink.set_property("max-buffers", 1)
            # appsink.set_property("qos", False)

        except Exception as e:
            print(f"âŒ [CRITICAL] íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None, None

    # def parse_skin_label(self, label_str):
    #     try:
    #         if ":" not in label_str: return None, None
    #         parts = label_str.split(":", 1)
    #         part_name = parts[0]; data_str = parts[1]; scores = {}
    #         for item in data_str.split(","):
    #             if ":" in item:
    #                 k, v = item.split(":"); scores[k] = int(v.replace("%", ""))
    #         return part_name, scores
    #     except: return None, None
    def parse_skin_label(self, label_str):
        try:
            if ":" not in label_str:
                return None, None

            # part_name ë¶„ë¦¬
            part_name, rest = label_str.split(":", 1)

            scores = {}
            for item in rest.split(","):
                if ":" in item:
                    k, v = item.split(":")

                    # %ê°€ ë¶™ì€ ê²½ìš° ì œê±°
                    v = v.replace("%", "")

                    # float ë³€í™˜ (ì—¬ê¸°ê°€ í•µì‹¬!)
                    try:
                        scores[k] = float(v)
                    except:
                        scores[k] = 0.0

            return part_name, scores
        except:
            return None, None

    # def process_measurement(self, detections):
    #     if self.measure_state in ["STANDBY", "DONE", "PROCESSING"]: return
    #     current_frame_data = {}; current_bboxes = {}; valid_parts_count = 0
    #     target_parts = ["chin", "lips", "right_cheek", "left_cheek", "right_eye", "left_eye", "forehead", "nose", "glabella"]
    #     for det in detections:
    #         label = det.get_label(); bbox = det.get_bbox()
    #         current_bboxes[label] = [bbox.xmin(), bbox.ymin(), bbox.width(), bbox.height()]
    #         if ":" in label:
    #             part_name, scores = self.parse_skin_label(label)
    #             if part_name and scores:
    #                 current_frame_data[part_name] = scores
    #                 if label in current_bboxes: current_bboxes[part_name] = current_bboxes.pop(label)
    #                 valid_parts_count += 1
    #         elif label in target_parts:
    #             valid_parts_count += 1
    #             current_frame_data[label] = {"Dry": random.randint(10,40),"Oil":random.randint(30,70),"Acne":random.randint(0,30),"Wrinkle":random.randint(0,50),"Pigment":random.randint(0,20)}
    #     if current_bboxes: self.last_bboxes = current_bboxes
    #     current_time = time.time()
    #     if self.measure_state == "IDLE":
    #         if valid_parts_count >= self.required_parts:
    #             self.measure_state = "READY"; self.start_time = current_time
    #             self.status_signal.emit("âœ… ì–¼êµ´ ì¸ì‹ë¨! 5ì´ˆê°„ ìœ ì§€í•˜ì„¸ìš”.")
    #         else: self.status_signal.emit(f"ê°€ê¹Œì´ ì˜¤ì„¸ìš” ({valid_parts_count}ë¶€ìœ„)")
    #     elif self.measure_state == "READY":
    #         if valid_parts_count < self.required_parts:
    #             print("self.measure_state = IDLE")
    #             self.measure_state = "IDLE"; self.status_signal.emit("ì–¼êµ´ì„ ë†“ì³¤ìŠµë‹ˆë‹¤.")
    #         elif current_time - self.start_time > 1.0:
    #             print("self.measure_state = MEASURING")
    #             self.measure_state = "MEASURING"; self.start_time = current_time
    #             self.collected_data.clear(); self.status_signal.emit("ì¸¡ì • ì¤‘... ğŸ“¸ (0%)")
    #     elif self.measure_state == "MEASURING":
    #         elapsed = current_time - self.start_time
    #         progress = min(100, int(elapsed / 5.0 * 100))
    #         self.status_signal.emit(f"ë¶„ì„ ì¤‘... {progress}%")
    #         print(f"current_frame_data",current_frame_data)
    #         for part, scores in current_frame_data.items(): self.collected_data[part].append(scores)
    #         if elapsed >= 5.0: self.finalize_measurement()

    def process_measurement(self, detections):
        if self.measure_state in ["STANDBY", "DONE", "PROCESSING"]:
            return

        current_frame_data = {}
        current_bboxes = {}
        valid_parts_count = 0

        TARGET_PARTS = [
            "chin", "lips", "right_cheek", "left_cheek",
            "right_eye", "left_eye", "forehead", "nose", "glabella"
        ]

        # C++ â†’ UI key ë³€í™˜
        KEY_MAP = {
            "wrinkle": "Wrinkle",
            "pigmentation": "Pigment",
            "pore": "Pore",
            "dryness": "Dry",
            "sagging": "Sagging"
        }

        # ê° ë¶€ìœ„ê°€ í•„ìš”í•œ ì§€í‘œ
        REGION_METRICS = {
            "forehead":     ["Wrinkle", "Pigment"],
            "glabella":     ["Wrinkle"],
            "left_eye":     ["Wrinkle"],
            "right_eye":    ["Wrinkle"],
            "left_cheek":   ["Pigment", "Pore"],
            "right_cheek":  ["Pigment", "Pore"],
            "lips":         ["Dry"],
            "chin":         ["Sagging"]
        }

        # -------------------------------
        # ğŸ”¥ 1) Detection & Regression íŒŒì‹±
        # -------------------------------
        for det in detections:

            label = det.get_label()           # ì˜ˆ: "right_cheek:3"
            base_label = label.split(":")[0]  # right_cheek

            bbox = det.get_bbox()

            cls = det.get_objects_typed(hailo.HAILO_CLASSIFICATION)

            # ===============================================
            # ğŸ”¥ íšŒê·€(Classification) ìˆëŠ” ê²½ìš° (í•µì‹¬)
            # ===============================================
            if len(cls) > 0:
                raw = cls[0].get_label()   # ì˜ˆ: right_cheek:pigmentation:1.53,pore:2.14
                print("ìƒíƒœë³„ ë“±ê¸‰", raw)

                part_name, raw_scores = self.parse_skin_label(raw)

                if part_name and raw_scores:

                    # UI keyë¡œ ë³€ê²½ (wrinkle â†’ Wrinkle)
                    fixed_scores = {}
                    for k, v in raw_scores.items():
                        ui_key = KEY_MAP.get(k)
                        if ui_key:
                            fixed_scores[ui_key] = float(v)

                    # ë¶€ìœ„ë³„ í•„ìš”í•œ ê°’ë§Œ ì €ì¥
                    need = REGION_METRICS.get(part_name, [])
                    filtered = {k: fixed_scores[k] for k in need if k in fixed_scores}

                    current_frame_data[part_name] = filtered

                    # ğŸ”¥ bboxëŠ” YOLO ë¼ë²¨ì´ ì•„ë‹ˆë¼ part_nameìœ¼ë¡œ ì €ì¥í•´ì•¼ í•¨
                    current_bboxes[part_name] = [
                        bbox.xmin(), bbox.ymin(), bbox.width(), bbox.height()
                    ]

                    valid_parts_count += 1
                    continue

            # ===============================================
            # ğŸ”¹ íšŒê·€ ì—†ëŠ” YOLO detection
            # ===============================================
            if base_label in TARGET_PARTS:
                current_frame_data[base_label] = {}
                current_bboxes[base_label] = [
                    bbox.xmin(), bbox.ymin(), bbox.width(), bbox.height()
                ]
                valid_parts_count += 1

        # -------------------------------
        # bbox ì „ì—­ ì €ì¥
        # -------------------------------
        if current_bboxes:
            self.last_bboxes = current_bboxes

        # -------------------------------
        # ğŸ”¥ 2) ìƒíƒœ ë¨¸ì‹ 
        # -------------------------------
        now = time.time()

        if self.measure_state == "IDLE":
            if valid_parts_count >= self.required_parts:
                self.measure_state = "READY"
                self.start_time = now
                self.status_signal.emit("âœ… ì–¼êµ´ ì¸ì‹ë¨! 5ì´ˆê°„ ìœ ì§€í•˜ì„¸ìš”.")
            else:
                self.status_signal.emit(f"ê°€ê¹Œì´ ì˜¤ì„¸ìš” ({valid_parts_count}ë¶€ìœ„)")

        elif self.measure_state == "READY":
            if valid_parts_count < self.required_parts:
                self.measure_state = "IDLE"
                self.status_signal.emit("ì–¼êµ´ì„ ë†“ì³¤ìŠµë‹ˆë‹¤.")
            elif now - self.start_time > 1.0:
                self.measure_state = "MEASURING"
                self.collected_data.clear()
                self.start_time = now
                self.status_signal.emit("ì¸¡ì • ì¤‘... ğŸ“¸ (0%)")

        elif self.measure_state == "MEASURING":
            elapsed = now - self.start_time
            progress = min(100, int(elapsed / 5.0 * 100))
            self.status_signal.emit(f"ë¶„ì„ ì¤‘... {progress}%")

            print("current_frame_data =", current_frame_data)

            # ğŸ”¥ ë¹ˆ dictë„ ì €ì¥ (ë¶€ìœ„ ì¡´ì¬ íŒì • ìœ„í•´)
            for part, scores in current_frame_data.items():
                rounded_scores = {k: round(v, 1) for k, v in scores.items()}
                self.collected_data[part].append(rounded_scores)

            if elapsed >= 5.0:
                self.finalize_measurement()


    # def finalize_measurement(self):
    #     self.measure_state = "PROCESSING"; print("ğŸ“Š ì¸¡ì • ì™„ë£Œ!")
    #     final_result = {}
    #     if not self.collected_data:
    #         print("ì¸¡ì • ì‹¤íŒ¨",self.collected_data)
    #         self.status_signal.emit("ì‹¤íŒ¨"); self.request_mirror_mode(); return
        
    #     total_severity = 0; total_count = 0
    #     for part, data_list in self.collected_data.items():
    #         if not data_list: continue
    #         avg_scores = {}; keys = data_list[0].keys()
    #         for k in keys:
    #             vals = [d.get(k, 0) for d in data_list]
    #             avg_val = int(sum(vals) / len(vals))
    #             avg_scores[k] = avg_val
    #             total_severity += avg_val; total_count += 1
    #         final_result[part] = avg_scores
        
    #     avg_sev = int(total_severity / total_count) if total_count > 0 else 0
    #     summary_score = max(0, 100 - avg_sev)

        
    #     safe_snapshot = self.last_frame.copy() if self.last_frame else None
    #     result_pack = {"score":summary_score, "time":time.strftime("%Y-%m-%d %H:%M"), "details":final_result, "snapshot":safe_snapshot, "bboxes":self.last_bboxes}
    #     self.result_signal.emit(result_pack); self.status_signal.emit("ë¶„ì„ ì™„ë£Œ!"); self.request_mirror_mode()
    def finalize_measurement(self):
        self.measure_state = "PROCESSING"
        print("ğŸ“Š ì¸¡ì • ì™„ë£Œ!")

        final_result = {}
        if not self.collected_data:
            print("ì¸¡ì • ì‹¤íŒ¨", self.collected_data)
            self.status_signal.emit("ì‹¤íŒ¨")
            self.request_mirror_mode()
            return

        MODEL_MAX = 3.0
        REAL_MAX = 5.0

        total_severity = 0.0
        total_count = 0

        for part, data_list in self.collected_data.items():
            if not data_list:
                continue

            avg_scores = {}
            keys = data_list[0].keys()

            for k in keys:
                raw_vals = [float(d.get(k, 0.0)) for d in data_list]
                raw_avg = sum(raw_vals) / len(raw_vals)

                # UI í‘œì‹œëŠ” ì›ë³¸ ë“±ê¸‰ ê·¸ëŒ€ë¡œ
                avg_scores[k] = round(raw_avg, 2)

                # ğŸ”¥ ì ìˆ˜ ê³„ì‚° ì‹œì—ë§Œ ì™„í™”ëœ severity ì‚¬ìš©
                # ê¸°ì¡´ raw/3 â†’ ì´ì œ raw/5 ë¡œ ì™„í™” (ì ìˆ˜ ìƒìŠ¹í•¨)
                severity_for_score = raw_avg / REAL_MAX

                total_severity += severity_for_score
                total_count += 1

            final_result[part] = avg_scores

        # ------------------------------
        # ì ìˆ˜ ê³„ì‚°
        # ------------------------------
        avg_sev = (total_severity / total_count) if total_count > 0 else 0
        summary_score = max(0, int(100 - avg_sev * 100))

        # ------------------------------
        # ê²°ê³¼ ì „ë‹¬
        # ------------------------------
        safe_snapshot = self.last_frame.copy() if self.last_frame else None

        result_pack = {
            "score": summary_score,
            "time": time.strftime("%Y-%m-%d %H:%M"),
            "details": final_result,
            "snapshot": safe_snapshot,
            "bboxes": self.last_bboxes
        }

        self.result_signal.emit(result_pack)
        self.status_signal.emit("ë¶„ì„ ì™„ë£Œ!")
        self.request_mirror_mode()


    def run(self):
        print("ğŸ§  ìŠ¤ë ˆë“œ ë£¨í”„ ì‹œì‘")
        while self.running:
            if self.requested_mode != self.active_mode:
                print(f"ğŸ”„ ëª¨ë“œ ë³€ê²½: {self.active_mode} -> {self.requested_mode}")
                self.stop_pipeline()
                time.sleep(1.5)
                self.pipeline, self.appsink = self._build_pipeline(self.requested_mode)
                if self.pipeline:
                    self.pipeline.set_state(Gst.State.PLAYING)
                    self.active_mode = self.requested_mode
                    if self.active_mode == 'MIRROR': self.mirror_ready_signal.emit()
                else:
                    time.sleep(1); continue

            if self.pipeline and self.appsink:
                try:
                    sample = self.appsink.emit("pull-sample")
                    if sample:
                        buf = sample.get_buffer()
                        if buf.get_size() < 200000: continue
                        
                        caps = sample.get_caps()
                        h = caps.get_structure(0).get_value("height")
                        w = caps.get_structure(0).get_value("width")
                        buffer = buf.extract_dup(0, buf.get_size())
                        frame = np.ndarray((h, w, 3), buffer=buffer, dtype=np.uint8)
                        
                        if w != 640:
                            import cv2
                            frame = cv2.resize(frame, (640, 640))
                        
                        q_img = QImage(frame.data, 640, 640, 640*3, QImage.Format_RGB888).copy()
                        if self.active_mode != 'SKIN_TYPE': self.last_frame = q_img.copy()
                        self.change_pixmap_signal.emit(q_img)

                        roi = hailo.get_roi_from_buffer(buf)
                        if self.active_mode == 'SKIN_TYPE':
                            self.process_skin_type_from_tensor(roi)
                        elif self.active_mode == 'AI':
                            dets = roi.get_objects_typed(hailo.HAILO_DETECTION)
                            self.process_measurement(dets)
                    else: time.sleep(0.005)
                except Exception as e: pass
            else: time.sleep(0.1)
        self.stop_pipeline()

    def stop(self):
        self.running = False
        self.wait()
